{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f03e0a",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f98c2c",
   "metadata": {},
   "source": [
    "Por incompatibilidades entre librerias nos vemos obligados a hacer este workaround para que solucionar los problemas de dependencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43a3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\anaconda3\\envs\\tfg\\lib\\site-packages\\statsmodels\\compat\\pandas.py:61: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "import  scipy.signal.signaltools\n",
    "import numpy as np\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    newsize = np.asarray(newsize)\n",
    "    currsize = np.array(arr.shape)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "scipy.signal.signaltools._centered = _centered\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "import pytorch_forecasting\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from  scipy.signal.signaltools import _centered\n",
    "from tft_helper import get_best_lr, tft_trainer, tft_predict, run_hyperparameter_optimization, save_exp_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82736cf5",
   "metadata": {},
   "source": [
    "# PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f8001a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model_days = 365\n",
    "validation_days = 14\n",
    "# test_days = 15\n",
    "n_prev_hours = 24* 6\n",
    "group = 'week'\n",
    "epochs = 1\n",
    "exp_path = 'TFT_experiments.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "lr_finder = False\n",
    "train_first = True\n",
    "grid_search = False\n",
    "\n",
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "# logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "\n",
    "#TFT params\n",
    "tft_params =  {'gradient_clip_val': 0.010584137969017322, 'hidden_size': 36, 'dropout': 0.2960659121982872, 'hidden_continuous_size': 22, 'attention_head_size': 4, 'learning_rate': 0.0010322318420096076}\n",
    "\n",
    "# {'early_stop_callback': early_stop_callback ,'gradient_clip_val': 0.46964879113018865, 'hidden_size': 8, 'dropout': 0.10391553098833228, 'hidden_continuous_size': 8, 'attention_head_size': 4, 'learning_rate': 0.2855372166883186}\n",
    "\n",
    "\n",
    "hyperparams_grid = {\n",
    "    \"gradient_clip_val_range\": (0.01, 1.0),\n",
    "    \"hidden_size_range\": (8, 64),\n",
    "    \"hidden_continuous_size_range\": (8, 64),\n",
    "    \"attention_head_size_range\": (1, 4),\n",
    "    \"learning_rate_range\": (0.001, 0.3),\n",
    "    \"dropout_range\": (0.1, 0.3),\n",
    "    \"trainer_kwargs\": dict(limit_train_batches=60),\n",
    "    \"reduce_on_plateau_patience\": 4,\n",
    "    \"use_learning_rate_finder\": False\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032f7e1",
   "metadata": {
    "id": "8032f7e1"
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62273f81",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "file_path =  './datasets/dataset_input_v1.xlsx'\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "df = df.rename(columns={'EUA': 'co2'})\n",
    "df['fechaHora'] = pd.to_datetime(df['fechaHora'])\n",
    "\n",
    "df = df.dropna(subset=['precio_spot'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a9e0d0",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fechaHora</th>\n",
       "      <th>precio_spot</th>\n",
       "      <th>demanda</th>\n",
       "      <th>co2</th>\n",
       "      <th>precio_gas</th>\n",
       "      <th>prod_eolica</th>\n",
       "      <th>prod_solar</th>\n",
       "      <th>demanda_residual</th>\n",
       "      <th>rampa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>66.88</td>\n",
       "      <td>22781.000000</td>\n",
       "      <td>24.18</td>\n",
       "      <td>24.45</td>\n",
       "      <td>3782.166667</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>19101.300</td>\n",
       "      <td>824.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>21448.500000</td>\n",
       "      <td>24.18</td>\n",
       "      <td>24.45</td>\n",
       "      <td>3740.333333</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>17924.100</td>\n",
       "      <td>1177.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>63.64</td>\n",
       "      <td>20262.166667</td>\n",
       "      <td>24.18</td>\n",
       "      <td>24.45</td>\n",
       "      <td>3711.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>16725.000</td>\n",
       "      <td>1199.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>58.85</td>\n",
       "      <td>19463.500000</td>\n",
       "      <td>24.18</td>\n",
       "      <td>24.45</td>\n",
       "      <td>3530.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15826.800</td>\n",
       "      <td>898.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 05:00:00</td>\n",
       "      <td>55.47</td>\n",
       "      <td>19164.000000</td>\n",
       "      <td>24.18</td>\n",
       "      <td>24.45</td>\n",
       "      <td>3390.166667</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15769.300</td>\n",
       "      <td>57.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46531</th>\n",
       "      <td>2024-04-22 19:00:00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>27209.083000</td>\n",
       "      <td>64.54</td>\n",
       "      <td>30.43</td>\n",
       "      <td>11333.333000</td>\n",
       "      <td>9408.916667</td>\n",
       "      <td>10095.400</td>\n",
       "      <td>-5391.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46532</th>\n",
       "      <td>2024-04-22 20:00:00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>29248.333000</td>\n",
       "      <td>64.54</td>\n",
       "      <td>30.43</td>\n",
       "      <td>13670.417000</td>\n",
       "      <td>3038.250000</td>\n",
       "      <td>16069.450</td>\n",
       "      <td>-5974.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46533</th>\n",
       "      <td>2024-04-22 21:00:00</td>\n",
       "      <td>12.81</td>\n",
       "      <td>30731.833000</td>\n",
       "      <td>64.54</td>\n",
       "      <td>30.43</td>\n",
       "      <td>13265.333000</td>\n",
       "      <td>1025.916667</td>\n",
       "      <td>17111.625</td>\n",
       "      <td>-1042.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46534</th>\n",
       "      <td>2024-04-22 22:00:00</td>\n",
       "      <td>7.62</td>\n",
       "      <td>28432.417000</td>\n",
       "      <td>64.54</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12733.917000</td>\n",
       "      <td>932.833333</td>\n",
       "      <td>14830.575</td>\n",
       "      <td>2281.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46535</th>\n",
       "      <td>2024-04-22 23:00:00</td>\n",
       "      <td>5.54</td>\n",
       "      <td>25648.917000</td>\n",
       "      <td>64.54</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12144.333000</td>\n",
       "      <td>906.916667</td>\n",
       "      <td>12823.700</td>\n",
       "      <td>2006.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46536 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                fechaHora  precio_spot       demanda    co2  precio_gas  \\\n",
       "0     2019-01-01 01:00:00        66.88  22781.000000  24.18       24.45   \n",
       "1     2019-01-01 02:00:00        66.00  21448.500000  24.18       24.45   \n",
       "2     2019-01-01 03:00:00        63.64  20262.166667  24.18       24.45   \n",
       "3     2019-01-01 04:00:00        58.85  19463.500000  24.18       24.45   \n",
       "4     2019-01-01 05:00:00        55.47  19164.000000  24.18       24.45   \n",
       "...                   ...          ...           ...    ...         ...   \n",
       "46531 2024-04-22 19:00:00         0.45  27209.083000  64.54       30.43   \n",
       "46532 2024-04-22 20:00:00         6.00  29248.333000  64.54       30.43   \n",
       "46533 2024-04-22 21:00:00        12.81  30731.833000  64.54       30.43   \n",
       "46534 2024-04-22 22:00:00         7.62  28432.417000  64.54       30.43   \n",
       "46535 2024-04-22 23:00:00         5.54  25648.917000  64.54       30.43   \n",
       "\n",
       "        prod_eolica   prod_solar  demanda_residual     rampa  \n",
       "0       3782.166667    29.166667         19101.300   824.100  \n",
       "1       3740.333333    23.500000         17924.100  1177.200  \n",
       "2       3711.500000    14.000000         16725.000  1199.100  \n",
       "3       3530.000000    14.000000         15826.800   898.200  \n",
       "4       3390.166667    14.000000         15769.300    57.500  \n",
       "...             ...          ...               ...       ...  \n",
       "46531  11333.333000  9408.916667         10095.400 -5391.325  \n",
       "46532  13670.417000  3038.250000         16069.450 -5974.050  \n",
       "46533  13265.333000  1025.916667         17111.625 -1042.175  \n",
       "46534  12733.917000   932.833333         14830.575  2281.050  \n",
       "46535  12144.333000   906.916667         12823.700  2006.875  \n",
       "\n",
       "[46536 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a04371",
   "metadata": {},
   "source": [
    "<!-- ## DF FINL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60de3a92",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicov\\AppData\\Local\\Temp\\ipykernel_7780\\866086546.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_last.loc[:,'precio_spot'] = np.where(df_last['precio_spot'] < 0, 0, df_last['precio_spot'])\n"
     ]
    }
   ],
   "source": [
    "now = pd.Timestamp.now()\n",
    "last_day = df['fechaHora'].iloc[-1]\n",
    "# Calcula la fecha hace dos meses utilizando timedelta\n",
    "fecha_start = (last_day - pd.Timedelta(days=model_days)).replace(hour=0, minute=0, second=0)\n",
    "\n",
    "# Filtra las filas \n",
    "df_last = df[df['fechaHora'] >= fecha_start]\n",
    "df_last.loc[:,'precio_spot'] = np.where(df_last['precio_spot'] < 0, 0, df_last['precio_spot'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8361298a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8785 entries, 37751 to 46535\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   fechaHora         8785 non-null   datetime64[ns]\n",
      " 1   precio_spot       8785 non-null   float64       \n",
      " 2   demanda           8785 non-null   float64       \n",
      " 3   co2               8785 non-null   float64       \n",
      " 4   precio_gas        8785 non-null   float64       \n",
      " 5   prod_eolica       8785 non-null   float64       \n",
      " 6   prod_solar        8785 non-null   float64       \n",
      " 7   demanda_residual  8785 non-null   float64       \n",
      " 8   rampa             8785 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(8)\n",
      "memory usage: 686.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_last.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2926d439",
   "metadata": {},
   "source": [
    "## DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "addff42d",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "data = df_last.copy()\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.drop_duplicates('fechaHora', keep='last')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88078ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['fechaHora'] < '2024-04-21 00:00:00']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d63dd4",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data['month'] = data['fechaHora'].dt.to_period('M').astype(str).astype('category').cat.codes\n",
    "data['week'] = data['fechaHora'].dt.strftime('%Y-%U').astype(str).astype('category').cat.codes\n",
    "# data['day'] = data['fechaHora'].dt.day.astype('category').cat.codes\n",
    "\n",
    "data['day'] = (data['fechaHora'] - data['fechaHora'].min()).dt.days\n",
    "data['hour'] = data['fechaHora'].dt.hour\n",
    "\n",
    "\n",
    "data['time_idx'] = data.groupby(group).cumcount() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eab0c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fechaHora</th>\n",
       "      <th>precio_spot</th>\n",
       "      <th>demanda</th>\n",
       "      <th>co2</th>\n",
       "      <th>precio_gas</th>\n",
       "      <th>prod_eolica</th>\n",
       "      <th>prod_solar</th>\n",
       "      <th>demanda_residual</th>\n",
       "      <th>rampa</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-23 00:00:00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>20607.000</td>\n",
       "      <td>88.76</td>\n",
       "      <td>34.59</td>\n",
       "      <td>8589.917</td>\n",
       "      <td>346.333333</td>\n",
       "      <td>12367.325</td>\n",
       "      <td>2025.075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-23 01:00:00</td>\n",
       "      <td>97.52</td>\n",
       "      <td>19405.250</td>\n",
       "      <td>88.76</td>\n",
       "      <td>34.59</td>\n",
       "      <td>8951.833</td>\n",
       "      <td>238.666667</td>\n",
       "      <td>10871.725</td>\n",
       "      <td>1495.600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-23 02:00:00</td>\n",
       "      <td>95.02</td>\n",
       "      <td>18445.833</td>\n",
       "      <td>88.76</td>\n",
       "      <td>34.59</td>\n",
       "      <td>9192.583</td>\n",
       "      <td>236.666667</td>\n",
       "      <td>9538.450</td>\n",
       "      <td>1333.275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-23 03:00:00</td>\n",
       "      <td>89.44</td>\n",
       "      <td>17952.000</td>\n",
       "      <td>88.76</td>\n",
       "      <td>34.59</td>\n",
       "      <td>9227.917</td>\n",
       "      <td>217.916667</td>\n",
       "      <td>8763.675</td>\n",
       "      <td>774.775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-23 04:00:00</td>\n",
       "      <td>86.67</td>\n",
       "      <td>17793.000</td>\n",
       "      <td>88.76</td>\n",
       "      <td>34.59</td>\n",
       "      <td>8885.250</td>\n",
       "      <td>211.416667</td>\n",
       "      <td>8246.650</td>\n",
       "      <td>517.025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>2024-04-20 19:00:00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>23285.833</td>\n",
       "      <td>66.94</td>\n",
       "      <td>30.43</td>\n",
       "      <td>9516.833</td>\n",
       "      <td>6549.166667</td>\n",
       "      <td>9076.925</td>\n",
       "      <td>-4252.825</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>363</td>\n",
       "      <td>19</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8733</th>\n",
       "      <td>2024-04-20 20:00:00</td>\n",
       "      <td>7.88</td>\n",
       "      <td>24815.083</td>\n",
       "      <td>66.94</td>\n",
       "      <td>30.43</td>\n",
       "      <td>11538.750</td>\n",
       "      <td>1462.833333</td>\n",
       "      <td>13523.325</td>\n",
       "      <td>-4446.400</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>363</td>\n",
       "      <td>20</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8734</th>\n",
       "      <td>2024-04-20 21:00:00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>26729.000</td>\n",
       "      <td>66.94</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12262.667</td>\n",
       "      <td>315.250000</td>\n",
       "      <td>14761.325</td>\n",
       "      <td>-1238.000</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>363</td>\n",
       "      <td>21</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8735</th>\n",
       "      <td>2024-04-20 22:00:00</td>\n",
       "      <td>8.58</td>\n",
       "      <td>25400.167</td>\n",
       "      <td>66.94</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12260.583</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>13095.525</td>\n",
       "      <td>1665.800</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>363</td>\n",
       "      <td>22</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8736</th>\n",
       "      <td>2024-04-20 23:00:00</td>\n",
       "      <td>7.54</td>\n",
       "      <td>23627.000</td>\n",
       "      <td>66.94</td>\n",
       "      <td>30.43</td>\n",
       "      <td>11933.083</td>\n",
       "      <td>103.916667</td>\n",
       "      <td>11596.625</td>\n",
       "      <td>1498.900</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>363</td>\n",
       "      <td>23</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8736 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               fechaHora  precio_spot    demanda    co2  precio_gas  \\\n",
       "0    2023-04-23 00:00:00       108.00  20607.000  88.76       34.59   \n",
       "1    2023-04-23 01:00:00        97.52  19405.250  88.76       34.59   \n",
       "2    2023-04-23 02:00:00        95.02  18445.833  88.76       34.59   \n",
       "3    2023-04-23 03:00:00        89.44  17952.000  88.76       34.59   \n",
       "4    2023-04-23 04:00:00        86.67  17793.000  88.76       34.59   \n",
       "...                  ...          ...        ...    ...         ...   \n",
       "8732 2024-04-20 19:00:00         3.25  23285.833  66.94       30.43   \n",
       "8733 2024-04-20 20:00:00         7.88  24815.083  66.94       30.43   \n",
       "8734 2024-04-20 21:00:00        10.00  26729.000  66.94       30.43   \n",
       "8735 2024-04-20 22:00:00         8.58  25400.167  66.94       30.43   \n",
       "8736 2024-04-20 23:00:00         7.54  23627.000  66.94       30.43   \n",
       "\n",
       "      prod_eolica   prod_solar  demanda_residual     rampa  month  week  day  \\\n",
       "0        8589.917   346.333333         12367.325  2025.075      0     0    0   \n",
       "1        8951.833   238.666667         10871.725  1495.600      0     0    0   \n",
       "2        9192.583   236.666667          9538.450  1333.275      0     0    0   \n",
       "3        9227.917   217.916667          8763.675   774.775      0     0    0   \n",
       "4        8885.250   211.416667          8246.650   517.025      0     0    0   \n",
       "...           ...          ...               ...       ...    ...   ...  ...   \n",
       "8732     9516.833  6549.166667          9076.925 -4252.825     12    52  363   \n",
       "8733    11538.750  1462.833333         13523.325 -4446.400     12    52  363   \n",
       "8734    12262.667   315.250000         14761.325 -1238.000     12    52  363   \n",
       "8735    12260.583   234.500000         13095.525  1665.800     12    52  363   \n",
       "8736    11933.083   103.916667         11596.625  1498.900     12    52  363   \n",
       "\n",
       "      hour  time_idx  \n",
       "0        0         0  \n",
       "1        1         1  \n",
       "2        2         2  \n",
       "3        3         3  \n",
       "4        4         4  \n",
       "...    ...       ...  \n",
       "8732    19       163  \n",
       "8733    20       164  \n",
       "8734    21       165  \n",
       "8735    22       166  \n",
       "8736    23       167  \n",
       "\n",
       "[8736 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fc650",
   "metadata": {},
   "source": [
    "## TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afdbea69",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\anaconda3\\envs\\tfg\\lib\\site-packages\\pytorch_forecasting\\data\\encoders.py:318: UserWarning: Found 1 unknown classes which were set to NaN\n",
      "  warnings.warn(\n",
      "c:\\Users\\nicov\\anaconda3\\envs\\tfg\\lib\\site-packages\\pytorch_forecasting\\data\\encoders.py:318: UserWarning: Found 1 unknown classes which were set to NaN\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = [col for col in data.columns if col != 'precio_spot' ]  # Columnas de características and col != 'fechaHora'\n",
    "\n",
    "max_prediction_length = 24\n",
    "max_encoder_length = n_prev_hours #48\n",
    "# training_cutoff = data[\"fechaHora\"].max() - pd.Timedelta(hours=max_encoder_length)\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "\n",
    "train = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"precio_spot\",\n",
    "    group_ids=[\"week\"],\n",
    "   min_encoder_length=24,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    #min_prediction_length=24,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[], # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=features,\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=['precio_spot'],\n",
    "    lags={'precio_spot': [24,48,72]},\n",
    "    target_normalizer=GroupNormalizer('robust',\n",
    "        groups=['week'],\n",
    "        transformation=\"softplus\"\n",
    "    ),\n",
    "  \n",
    "   # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    # add_encoder_length=True,\n",
    "    categorical_encoders={\n",
    "        'month':pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        'week':pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        'day':pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \n",
    "    },\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(train, data, predict=True, stop_randomization=True)\n",
    "# test = TimeSeriesDataSet.from_dataset(training, test_data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 64  # set this between 32 to 128\n",
    "train_dataloader = train.to_dataloader(train=True, batch_size=batch_size, num_workers=11, persistent_workers=True)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=11, persistent_workers=True)\n",
    "# test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=11, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1db5ef6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesDataSet[length=52](\n",
       "\ttime_idx='time_idx',\n",
       "\ttarget='precio_spot',\n",
       "\tgroup_ids=['week'],\n",
       "\tweight=None,\n",
       "\tmax_encoder_length=144,\n",
       "\tmin_encoder_length=24,\n",
       "\tmin_prediction_idx=0,\n",
       "\tmin_prediction_length=24,\n",
       "\tmax_prediction_length=24,\n",
       "\tstatic_categoricals=[],\n",
       "\tstatic_reals=['encoder_length', 'precio_spot_center', 'precio_spot_scale'],\n",
       "\ttime_varying_known_categoricals=[],\n",
       "\ttime_varying_known_reals=['fechaHora', 'demanda', 'co2', 'precio_gas', 'prod_eolica', 'prod_solar', 'demanda_residual', 'rampa', 'month', 'week', 'day', 'hour', 'time_idx', 'relative_time_idx', 'precio_spot_lagged_by_24', 'precio_spot_lagged_by_48', 'precio_spot_lagged_by_72'],\n",
       "\ttime_varying_unknown_categoricals=[],\n",
       "\ttime_varying_unknown_reals=['precio_spot'],\n",
       "\tvariable_groups={},\n",
       "\tconstant_fill_strategy={},\n",
       "\tallow_missing_timesteps=False,\n",
       "\tlags={'precio_spot': [24, 48, 72]},\n",
       "\tadd_relative_time_idx=True,\n",
       "\tadd_target_scales=True,\n",
       "\tadd_encoder_length=True,\n",
       "\ttarget_normalizer=GroupNormalizer(\n",
       "\tmethod='robust',\n",
       "\tgroups=['week'],\n",
       "\tcenter=True,\n",
       "\tscale_by_group=False,\n",
       "\ttransformation='softplus',\n",
       "\tmethod_kwargs={}\n",
       "),\n",
       "\tcategorical_encoders={'month': NaNLabelEncoder(add_nan=True, warn=True), 'week': NaNLabelEncoder(add_nan=True, warn=True), 'day': NaNLabelEncoder(add_nan=True, warn=True), '__group_id__week': NaNLabelEncoder(add_nan=False, warn=True)},\n",
       "\tscalers={'encoder_length': StandardScaler(), 'precio_spot_center': StandardScaler(), 'precio_spot_scale': StandardScaler(), 'fechaHora': StandardScaler(), 'demanda': StandardScaler(), 'co2': StandardScaler(), 'precio_gas': StandardScaler(), 'prod_eolica': StandardScaler(), 'prod_solar': StandardScaler(), 'demanda_residual': StandardScaler(), 'rampa': StandardScaler(), 'month': StandardScaler(), 'week': StandardScaler(), 'day': StandardScaler(), 'hour': StandardScaler(), 'time_idx': StandardScaler(), 'relative_time_idx': StandardScaler()},\n",
       "\trandomize_length=None,\n",
       "\tpredict_mode=True\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b5bd2",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a24e8",
   "metadata": {},
   "source": [
    "## LEARNIG RATE FINDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa807d",
   "metadata": {},
   "source": [
    "En primer lugar realizamos un estudio para hallar de forma aproximada el valor optimo de tasa de aprendizaje.  No es recomendable al 100% usar el valor sugerido directamente pues a veces no encuentra el mejor, sin embargo si que da un muy buen punto de partida por donde empezar a probar. Para ello usamos un modelo TFT cualquiera basico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54055c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lr_finder:\n",
    "    res = get_best_lr(train, train_dataloader, val_dataloader, **tft_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1bdeb0",
   "metadata": {},
   "source": [
    "Tras ejecutar este trozo de codigo varias veces podemos concluir que la learning rate optima esta entre 0,1 y 0,2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927621bc",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "152ce290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\nicov\\anaconda3\\envs\\tfg\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\nicov\\anaconda3\\envs\\tfg\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:199: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0     \n",
      "3  | prescalers                         | ModuleDict                      | 924   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 8.9 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 61.0 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 57.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 5.4 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 5.4 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 5.4 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 5.4 K \n",
      "11 | lstm_encoder                       | LSTM                            | 10.7 K\n",
      "12 | lstm_decoder                       | LSTM                            | 10.7 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.7 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 72    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 6.7 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 3.3 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.7 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 5.4 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.7 K \n",
      "20 | output_layer                       | Linear                          | 259   \n",
      "----------------------------------------------------------------------------------------\n",
      "193 K     Trainable params\n",
      "0         Non-trainable params\n",
      "193 K     Total params\n",
      "0.772     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\anaconda3\\envs\\tfg\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:298: The number of training batches (39) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 39/39 [00:27<00:00,  1.42it/s, v_num=20, train_loss_step=10.60, val_loss=11.60, train_loss_epoch=18.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 39/39 [00:28<00:00,  1.38it/s, v_num=20, train_loss_step=10.60, val_loss=11.60, train_loss_epoch=18.20]\n",
      "Number of parameters in network: 193.1k\n",
      "        model_name       loss  epochs  gradient_clip_val  hidden_size  \\\n",
      "0   simple_365_144  10.491350       1           0.010584           36   \n",
      "1   simple_365_144  10.491350       1           0.010584           36   \n",
      "2   simple_365_144  10.491350       1           0.010584           36   \n",
      "3   simple_365_144  10.491350       1           0.010584           36   \n",
      "4   simple_365_144  10.491350       1           0.010584           36   \n",
      "5   simple_365_144  10.491350       1           0.010584           36   \n",
      "6   simple_365_144  10.491350       1           0.010584           36   \n",
      "7   simple_365_144  10.491350       1           0.010584           36   \n",
      "8   simple_365_144  10.491350       1           0.010584           36   \n",
      "9   simple_365_144  10.491350       1           0.010584           36   \n",
      "10  simple_365_144  10.491350       1           0.010584           36   \n",
      "11  simple_365_144  10.491350       1           0.010584           36   \n",
      "12  simple_365_144  10.491350       1           0.010584           36   \n",
      "13  simple_365_144  10.491350       1           0.010584           36   \n",
      "14  simple_365_144  10.491350       1           0.010584           36   \n",
      "15  simple_365_144  10.491350       1           0.010584           36   \n",
      "16  simple_365_144  10.491350       1           0.010584           36   \n",
      "17  simple_365_144  10.491350       1           0.010584           36   \n",
      "18  simple_365_144  11.565637       1           0.010584           36   \n",
      "\n",
      "     dropout  hidden_continuous_size  attention_head_size  learning_rate  \n",
      "0   0.296066                      22                    4            0.1  \n",
      "1   0.296066                      22                    4            0.1  \n",
      "2   0.296066                      22                    4            0.1  \n",
      "3   0.296066                      22                    4            0.1  \n",
      "4   0.296066                      22                    4            0.1  \n",
      "5   0.296066                      22                    4            0.1  \n",
      "6   0.296066                      22                    4            0.1  \n",
      "7   0.296066                      22                    4            0.1  \n",
      "8   0.296066                      22                    4            0.1  \n",
      "9   0.296066                      22                    4            0.1  \n",
      "10  0.296066                      22                    4            0.1  \n",
      "11  0.296066                      22                    4            0.1  \n",
      "12  0.296066                      22                    4            0.1  \n",
      "13  0.296066                      22                    4            0.1  \n",
      "14  0.296066                      22                    4            0.1  \n",
      "15  0.296066                      22                    4            0.1  \n",
      "16  0.296066                      22                    4            0.1  \n",
      "17  0.296066                      22                    4            0.1  \n",
      "18  0.296066                      22                    4            0.1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\Documents\\Github\\SPOT-Price-Forecast-NN\\src\\tft_helper.py:179: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tft_exps = tft_exps.append(new_exp, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "if train_first:\n",
    "    tft_params['learning_rate'] =  0.1\n",
    "\n",
    "    tft, val_loss = tft_trainer(train, train_dataloader, val_dataloader, max_epochs=epochs, save_model=False, **tft_params)\n",
    "    save_exp_results(exp_path, tft_params, model_days, n_prev_hours, val_loss, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f0114",
   "metadata": {},
   "source": [
    "### EVAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba6ae28f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TemporalFusionTransformer' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_first:\n\u001b[1;32m----> 2\u001b[0m     tft_predict(\u001b[43mtft\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, val_dataloader, n_preds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TemporalFusionTransformer' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "if train_first:\n",
    "    tft_predict(tft[0], val_dataloader, n_preds=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4ad1d",
   "metadata": {},
   "source": [
    "## GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search:\n",
    "    study, best_tft = run_hyperparameter_optimization(train, train_dataloader, val_dataloader, n_trials=50, max_epochs=30, **hyperparams_grid)\n",
    "    print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2020b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a58890",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = {'gradient_clip_val': 0.022997345678533884, 'hidden_size': 12, 'dropout': 0.2243809465682846, 'hidden_continuous_size': 8, 'attention_head_size': 4, 'learning_rate': 0.0038729048630587303}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab688c9",
   "metadata": {},
   "source": [
    "Podemos cortar la ejecucion y reanudarla posteriormente si habilitamos las siguientes lineas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac14e25",
   "metadata": {},
   "source": [
    "### EVAL BEST FOUND MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search:\n",
    "    tft_predict(best_tft, val_dataloader, n_preds=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b6560",
   "metadata": {},
   "source": [
    "# TEST EVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bcfc3f",
   "metadata": {},
   "source": [
    "## BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee697ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m tft\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mtest_dataloader\u001b[49m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = tft.predict(test_dataloader, mode=\"raw\", return_x=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(predictions.output[0].shape[0]):  # plot 10 examples\n",
    "    tft.plot_prediction(predictions.x, predictions.output, idx=idx, add_loss_to_title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28b921",
   "metadata": {},
   "source": [
    "## GRID TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_tft.predict(test_dataloader, mode=\"raw\", return_x=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b55681",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(predictions.output[0].shape[0]):  # plot 10 examples\n",
    "    grid_tft.plot_prediction(predictions.x, predictions.output, idx=idx, add_loss_to_title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03dd31",
   "metadata": {},
   "source": [
    "# NEW PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e005dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[lambda x: x.week > x.week.max() - max_encoder_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85048ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_data = data[lambda x: x.month > x.month.max() - max_encoder_length]\n",
    "\n",
    "last_data = data[lambda x: x.month == x.month.max()]\n",
    "# Crear un rango de fechas para el periodo de predicción con frecuencia horaria\n",
    "date_range = pd.date_range(start=last_data['fechaHora'].max() + pd.DateOffset(hours=1),\n",
    "                           periods=max_prediction_length, freq='H')\n",
    "\n",
    "decoder_data = pd.DataFrame({'fechaHora': date_range})\n",
    "\n",
    "# Concatenar los DataFrames\n",
    "\n",
    "# # Asignar las fechas al DataFrame\n",
    "# decoder_data['fechaHora'] = date_range.repeat(len(last_data))\n",
    "\n",
    "# # Asegurarse de que el DataFrame resultante tenga las mismas columnas que last_data\n",
    "# decoder_data = decoder_data[last_data.columns]\n",
    "# # add time index consistent with \"data\"\n",
    "# decoder_data[\"month\"] = decoder_data[\"fechaHora\"].dt.year * 12 + decoder_data[\"fechaHora\"].dt.month\n",
    "# decoder_data[\"month\"] += encoder_data[\"month\"].max() + 1 - decoder_data[\"month\"].min()\n",
    "\n",
    "# adjust additional time feature(s)\n",
    "# decoder_data[\"month\"] = decoder_data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "\n",
    "# combine encoder and decoder data\n",
    "# new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_excel( os.path.join(PATHS['LOCAL']['root'], 'datasets', 'new_pred_input.xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['month'] = 12\n",
    "new_data['week'] = 53\n",
    "new_data = new_data.reset_index(drop=True)\n",
    "new_data['index'] = new_data.index\n",
    "new_data = new_data.fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = TimeSeriesDataSet.from_dataset(training, new_data, predict=True)\n",
    "raw_predictions = tft.predict(new_data, mode=\"raw\", return_index=True, return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b59384",
   "metadata": {},
   "outputs": [],
   "source": [
    "tft.plot_prediction(raw_predictions.x, raw_predictions.output, idx=0, add_loss_to_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b94fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "prediction_set = 3\n",
    "for i in range(raw_predictions.output.prediction[0].shape[0]):\n",
    "    prediction.append(float(raw_predictions.output.prediction[0][i][prediction_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710693a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(prediction)\n",
    "predictions_df.to_excel('pred2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9204d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = raw_predictions.output.prediction[0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(predictions.shape[1]):  \n",
    "    plt.plot(predictions[:, i], label=f\"Serie {i+1}\")\n",
    "\n",
    "plt.xlabel(\"Paso de tiempo\")\n",
    "plt.ylabel(\"Valor predicho\")\n",
    "plt.title(\"Predicciones para las 7 series temporales\")\n",
    "plt.legend()  \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
